import os
import xml.etree.ElementTree as ET
from glob import glob
import random
from shutil import copyfile
from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter Notebook compatibility

# Load class names from classes.txt
with open('classes.txt') as f:
    classes = f.read().strip().split()

# Helper function to convert bbox
def convert_bbox(size, box):
    dw = 1. / size[0]
    dh = 1. / size[1]
    x = (box[0] + box[1]) / 2.0 - 1
    y = (box[2] + box[3]) / 2.0 - 1
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x * dw
    w = w * dw
    y = y * dh
    h = h * dh
    return (x, y, w, h)

# Helper function to convert annotation
def convert_annotation(xml_path, output_path):
    tree = ET.parse(xml_path)
    root = tree.getroot()
    size = root.find('size')
    w = int(size.find('width').text)
    h = int(size.find('height').text)

    with open(output_path, 'w') as out_file:
        for obj in root.iter('object'):
            difficult = obj.find('difficult')
            if difficult is not None and difficult.text == '1':
                continue
            cls = obj.find('name').text
            if cls not in classes:
                continue
            cls_id = classes.index(cls)
            xmlbox = obj.find('bndbox')
            b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text),
                 float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))
            bbox = convert_bbox((w, h), b)
            out_file.write(f"{cls_id} " + " ".join([f"{a:.6f}" for a in bbox]) + '\n')

# Create directories for YOLO formatted dataset
os.makedirs('images/train', exist_ok=True)
os.makedirs('images/val', exist_ok=True)
os.makedirs('labels/train', exist_ok=True)
os.makedirs('labels/val', exist_ok=True)

# Split dataset into train and val sets
image_files = glob(os.path.join('images', '*.jpg'))
random.shuffle(image_files)
train_ratio = 0.8
train_size = int(train_ratio * len(image_files))
train_files = image_files[:train_size]
val_files = image_files[train_size:]

# Copy and convert annotations for training set
for img_file in tqdm(train_files, desc='Processing training files'):
    base_name = os.path.basename(img_file)
    copyfile(img_file, os.path.join('images/train', base_name))
    xml_file = os.path.join('labels', base_name.replace('.jpg', '.xml'))
    if os.path.exists(xml_file):
        convert_annotation(xml_file, os.path.join('labels/train', base_name.replace('.jpg', '.txt')))
    else:
        print(f"Warning: {xml_file} not found.")

# Copy and convert annotations for validation set
for img_file in tqdm(val_files, desc='Processing validation files'):
    base_name = os.path.basename(img_file)
    copyfile(img_file, os.path.join('images/val', base_name))
    xml_file = os.path.join('labels', base_name.replace('.jpg', '.xml'))
    if os.path.exists(xml_file):
        convert_annotation(xml_file, os.path.join('labels/val', base_name.replace('.jpg', '.txt')))
    else:
        print(f"Warning: {xml_file} not found.")
